{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giancarlohc/Applied-AI-in-Transportation/blob/main/Project/ProjectCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Processing\n"
      ],
      "metadata": {
        "id": "XVPBElITz1A5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Loading Data"
      ],
      "metadata": {
        "id": "dDvy2dMhz815"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EZectnFkmYWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc358e38-e9fe-443b-b5e8-ea43681748d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting researchpy\n",
            "  Downloading researchpy-0.3.5-py3-none-any.whl (33 kB)\n",
            "Collecting calmap\n",
            "  Downloading calmap-0.0.11-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from researchpy) (1.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from researchpy) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from researchpy) (1.5.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from researchpy) (0.14.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from researchpy) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from calmap) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calmap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->researchpy) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->researchpy) (1.16.0)\n",
            "Installing collected packages: calmap, researchpy\n",
            "Successfully installed calmap-0.0.11 researchpy-0.3.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install researchpy calmap\n",
        "import researchpy as rp\n",
        "import calmap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/giancarlohc/Applied-AI-in-Transportation/main/ProjectAssignmentData/Dataset-PT.csv\"\n",
        "dataset = pd.read_csv(url,skiprows=[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Data Exploration"
      ],
      "metadata": {
        "id": "_w_UzhEa0GQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "crr0GuH4bMKN",
        "outputId": "328bd038-81fd-4bd7-f9d3-303d4afe08f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Calendar_date  route_id  bus_id  stop_sequence  arrival_delay  \\\n",
              "0            20220108         4   41344              1            151   \n",
              "1            20220108         4   41344              2            185   \n",
              "2            20220108         4   41344              3            186   \n",
              "3            20220108         4   41344              4            202   \n",
              "4            20220108         4   41344              5            242   \n",
              "...               ...       ...     ...            ...            ...   \n",
              "545098       20220630         4   41362             23            344   \n",
              "545099       20220630         4   41362             24            330   \n",
              "545100       20220630         4   41362             25            339   \n",
              "545101       20220630         4   41362             26            331   \n",
              "545102       20220630         4   41362             27            264   \n",
              "\n",
              "        dwell_time  travel_time_for_previous_section  scheduled_travel_time  \\\n",
              "0                0                                 0                    120   \n",
              "1               24                               171                     45   \n",
              "2                0                                55                     41   \n",
              "3               12                                42                     94   \n",
              "4               21                                98                     86   \n",
              "...            ...                               ...                    ...   \n",
              "545098          13                                74                     44   \n",
              "545099          15                                34                     92   \n",
              "545100          17                                63                     43   \n",
              "545101           0                                35                     58   \n",
              "545102           0                                50                    107   \n",
              "\n",
              "        upstream_stop_delay  origin_delay  ...  factor(weather)Rain  \\\n",
              "0                       100           100  ...                    0   \n",
              "1                       151           100  ...                    0   \n",
              "2                       185           100  ...                    0   \n",
              "3                       186           100  ...                    0   \n",
              "4                       202           100  ...                    0   \n",
              "...                     ...           ...  ...                  ...   \n",
              "545098                  341            12  ...                    0   \n",
              "545099                  344            12  ...                    0   \n",
              "545100                  330            12  ...                    0   \n",
              "545101                  339            12  ...                    0   \n",
              "545102                  331            12  ...                    0   \n",
              "\n",
              "        factor(weather)Snow  factor(temperature)Cold  \\\n",
              "0                         0                        0   \n",
              "1                         0                        0   \n",
              "2                         0                        0   \n",
              "3                         0                        0   \n",
              "4                         0                        0   \n",
              "...                     ...                      ...   \n",
              "545098                    0                        0   \n",
              "545099                    0                        0   \n",
              "545100                    0                        0   \n",
              "545101                    0                        0   \n",
              "545102                    0                        0   \n",
              "\n",
              "        factor(temperature)Extra_cold factor(temperature)Normal  \\\n",
              "0                                   0                         1   \n",
              "1                                   0                         1   \n",
              "2                                   0                         1   \n",
              "3                                   0                         1   \n",
              "4                                   0                         1   \n",
              "...                               ...                       ...   \n",
              "545098                              0                         1   \n",
              "545099                              0                         1   \n",
              "545100                              0                         1   \n",
              "545101                              0                         1   \n",
              "545102                              0                         1   \n",
              "\n",
              "       factor(day_of_week)weekday factor(day_of_week)weekend  \\\n",
              "0                               0                          1   \n",
              "1                               0                          1   \n",
              "2                               0                          1   \n",
              "3                               0                          1   \n",
              "4                               0                          1   \n",
              "...                           ...                        ...   \n",
              "545098                          1                          0   \n",
              "545099                          1                          0   \n",
              "545100                          1                          0   \n",
              "545101                          1                          0   \n",
              "545102                          1                          0   \n",
              "\n",
              "       factor(time_of_day)Afternoon_peak  factor(time_of_day)Morning_peak  \\\n",
              "0                                      0                                0   \n",
              "1                                      0                                0   \n",
              "2                                      0                                0   \n",
              "3                                      0                                0   \n",
              "4                                      0                                0   \n",
              "...                                  ...                              ...   \n",
              "545098                                 0                                0   \n",
              "545099                                 0                                0   \n",
              "545100                                 0                                0   \n",
              "545101                                 0                                0   \n",
              "545102                                 0                                0   \n",
              "\n",
              "        factor(time_of_day)Off-peak  \n",
              "0                                 1  \n",
              "1                                 1  \n",
              "2                                 1  \n",
              "3                                 1  \n",
              "4                                 1  \n",
              "...                             ...  \n",
              "545098                            1  \n",
              "545099                            1  \n",
              "545100                            1  \n",
              "545101                            1  \n",
              "545102                            1  \n",
              "\n",
              "[545103 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b309052-6d51-4ef3-a8b3-85c19441825c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Calendar_date</th>\n",
              "      <th>route_id</th>\n",
              "      <th>bus_id</th>\n",
              "      <th>stop_sequence</th>\n",
              "      <th>arrival_delay</th>\n",
              "      <th>dwell_time</th>\n",
              "      <th>travel_time_for_previous_section</th>\n",
              "      <th>scheduled_travel_time</th>\n",
              "      <th>upstream_stop_delay</th>\n",
              "      <th>origin_delay</th>\n",
              "      <th>...</th>\n",
              "      <th>factor(weather)Rain</th>\n",
              "      <th>factor(weather)Snow</th>\n",
              "      <th>factor(temperature)Cold</th>\n",
              "      <th>factor(temperature)Extra_cold</th>\n",
              "      <th>factor(temperature)Normal</th>\n",
              "      <th>factor(day_of_week)weekday</th>\n",
              "      <th>factor(day_of_week)weekend</th>\n",
              "      <th>factor(time_of_day)Afternoon_peak</th>\n",
              "      <th>factor(time_of_day)Morning_peak</th>\n",
              "      <th>factor(time_of_day)Off-peak</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>2</td>\n",
              "      <td>185</td>\n",
              "      <td>24</td>\n",
              "      <td>171</td>\n",
              "      <td>45</td>\n",
              "      <td>151</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>3</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>41</td>\n",
              "      <td>185</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>4</td>\n",
              "      <td>202</td>\n",
              "      <td>12</td>\n",
              "      <td>42</td>\n",
              "      <td>94</td>\n",
              "      <td>186</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>5</td>\n",
              "      <td>242</td>\n",
              "      <td>21</td>\n",
              "      <td>98</td>\n",
              "      <td>86</td>\n",
              "      <td>202</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545098</th>\n",
              "      <td>20220630</td>\n",
              "      <td>4</td>\n",
              "      <td>41362</td>\n",
              "      <td>23</td>\n",
              "      <td>344</td>\n",
              "      <td>13</td>\n",
              "      <td>74</td>\n",
              "      <td>44</td>\n",
              "      <td>341</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545099</th>\n",
              "      <td>20220630</td>\n",
              "      <td>4</td>\n",
              "      <td>41362</td>\n",
              "      <td>24</td>\n",
              "      <td>330</td>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "      <td>92</td>\n",
              "      <td>344</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545100</th>\n",
              "      <td>20220630</td>\n",
              "      <td>4</td>\n",
              "      <td>41362</td>\n",
              "      <td>25</td>\n",
              "      <td>339</td>\n",
              "      <td>17</td>\n",
              "      <td>63</td>\n",
              "      <td>43</td>\n",
              "      <td>330</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545101</th>\n",
              "      <td>20220630</td>\n",
              "      <td>4</td>\n",
              "      <td>41362</td>\n",
              "      <td>26</td>\n",
              "      <td>331</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>58</td>\n",
              "      <td>339</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545102</th>\n",
              "      <td>20220630</td>\n",
              "      <td>4</td>\n",
              "      <td>41362</td>\n",
              "      <td>27</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>107</td>\n",
              "      <td>331</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545103 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b309052-6d51-4ef3-a8b3-85c19441825c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b309052-6d51-4ef3-a8b3-85c19441825c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b309052-6d51-4ef3-a8b3-85c19441825c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd554a10-35aa-44b0-b7b9-5f8737455a9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd554a10-35aa-44b0-b7b9-5f8737455a9d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd554a10-35aa-44b0-b7b9-5f8737455a9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "rEl8TvMGsK3X",
        "outputId": "fb7f4089-1c96-4074-ac4b-09611e162490"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b9f29c8a3530>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3428\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3432\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11845\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11846\u001b[0m         ):\n\u001b[0;32m> 11847\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11849\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11399\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11400\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11401\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  11402\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11403\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11351\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11352\u001b[0m             )\n\u001b[0;32m> 11353\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11354\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11355\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10854\u001b[0m             \u001b[0;31m# After possibly _get_data and transposing, we are now in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10855\u001b[0m             \u001b[0;31m#  simple case where we can use BlockManager.reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10856\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_failures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10857\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mres_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m             \u001b[0mnbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1570\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Split and operate column-by-column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_and_operate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msplit_and_operate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mres_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mrbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2036\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2037\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mblk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10825\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10826\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10827\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dataset[\"arrival_delay\"])"
      ],
      "metadata": {
        "id": "tfHyZhzju7oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.boxplot(column=[\"arrival_delay\",\"dwell_time\",\"travel_time_for_previous_section\",\"scheduled_travel_time\"])"
      ],
      "metadata": {
        "id": "VZCaTvpibGj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.boxplot(column=[\"upstream_stop_delay\",\"origin_delay\",\"previous_bus_delay\",\"previous_trip_travel_time\",\"traffic_condition\",\"recurrent_delay\"])"
      ],
      "metadata": {
        "id": "AD0rKo-qcwSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(dataset.isna())"
      ],
      "metadata": {
        "id": "SbnDS9OqdD14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = dataset[[\"arrival_delay\",\"dwell_time\",\"travel_time_for_previous_section\",\"scheduled_travel_time\",\"upstream_stop_delay\",\"origin_delay\",\"previous_bus_delay\",\"previous_trip_travel_time\",\"traffic_condition\",\"recurrent_delay\"]].corr()"
      ],
      "metadata": {
        "id": "yNLijMh8dDij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))  # Set figure size for better visualization\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gI5bHIV-dC3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rp.summary_cat(dataset[[\"weather\", \"temperature\",\"day_of_week\",\"time_of_day\"]])"
      ],
      "metadata": {
        "id": "zRpEKLqcfF6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dataset[\"Calendar_date\"])"
      ],
      "metadata": {
        "id": "JG7QcAGNfUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dates = pd.to_datetime(dataset['Calendar_date'], format='%Y%m%d')\n",
        "\n",
        "date_frequencies = dates.value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "date_frequencies.plot(kind='line', linestyle='-', marker='o')\n",
        "plt.title(\"Date Frequency\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gLjfcL-3iKLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "calmap.yearplot(date_frequencies, year=2022)\n",
        "plt.title(\"Date Frequency Heatmap for 2022\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DIntxnWzjDaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates"
      ],
      "metadata": {
        "id": "5IeePRrhjkLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0:5]['scheduled_travel_time'].sum()/60"
      ],
      "metadata": {
        "id": "KLDJ_oUwDWFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Creation of Training Datasets"
      ],
      "metadata": {
        "id": "-UvDpzFu0X23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.1 Creation of Datasets with 1,5,10,15,20 Stop Prediction"
      ],
      "metadata": {
        "id": "Avg29Lje0r1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "delayed5 = pd.DataFrame()\n",
        "delayed10 = pd.DataFrame()\n",
        "delayed15 = pd.DataFrame()\n",
        "delayed20 = pd.DataFrame()\n",
        "for k in set(dataset['Calendar_date']):\n",
        "  buses = set(dataset[dataset[\"Calendar_date\"]==k][\"bus_id\"])\n",
        "  for j in buses:\n",
        "    pullout = dataset[(dataset['bus_id'] == j) & (dataset['Calendar_date'] == k)]\n",
        "\n",
        "    pullout5 = pullout.copy()\n",
        "    pullout5['delayed_delay'] = pullout5['arrival_delay'].shift(-4)\n",
        "    pullout5 = pullout5.dropna()\n",
        "    delayed5 = pd.concat((delayed5,pullout5),axis=0)\n",
        "\n",
        "    pullout10 = pullout.copy()\n",
        "    pullout10['delayed_delay'] = pullout10['arrival_delay'].shift(-9)\n",
        "    pullout10 = pullout10.dropna()\n",
        "    delayed10 = pd.concat((delayed10,pullout10),axis=0)\n",
        "\n",
        "    pullout15 = pullout.copy()\n",
        "    pullout15['delayed_delay'] = pullout15['arrival_delay'].shift(-14)\n",
        "    pullout15 = pullout15.dropna()\n",
        "    delayed15 = pd.concat((delayed15,pullout15),axis=0)\n",
        "\n",
        "    pullout20 = pullout.copy()\n",
        "    pullout20['delayed_delay'] = pullout20['arrival_delay'].shift(-19)\n",
        "    pullout20 = pullout20.dropna()\n",
        "    delayed20 = pd.concat((delayed20,pullout20),axis=0)"
      ],
      "metadata": {
        "id": "NjncMo43D71N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delayed5"
      ],
      "metadata": {
        "id": "dVfhNxxdcl4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.2 Normalizing the Datasets"
      ],
      "metadata": {
        "id": "zjW4vo5E1Jun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-Score normalization handles outliers better (many in the dataset and important to detect)"
      ],
      "metadata": {
        "id": "HIx_-PalmEsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnnames = dataset.columns\n",
        "numericcolumns = columnnames[4:14].tolist()\n",
        "numericcolumns.append(\"delayed_delay\")\n",
        "factorcolumns = columnnames[18:].tolist()\n",
        "columnstouse = numericcolumns + factorcolumns"
      ],
      "metadata": {
        "id": "nsp5RC2yoD-b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "delayed5[numericcolumns] = scaler.fit_transform(delayed5[numericcolumns])\n",
        "delayed10[numericcolumns] = scaler.fit_transform(delayed10[numericcolumns])\n",
        "delayed15[numericcolumns] = scaler.fit_transform(delayed15[numericcolumns])\n",
        "delayed20[numericcolumns] = scaler.fit_transform(delayed20[numericcolumns])"
      ],
      "metadata": {
        "id": "DoG5vk1FjT0z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delayed5 = delayed5[columnstouse]\n",
        "delayed10 = delayed10[columnstouse]\n",
        "delayed15 = delayed15[columnstouse]\n",
        "delayed20 = delayed20[columnstouse]"
      ],
      "metadata": {
        "id": "xrrDEM15swKX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFHs4Cjxt372"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.3 Splitting the Datasets into Training and Test 80/20%"
      ],
      "metadata": {
        "id": "xOpzQ6Ux1Ult"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y5 = delayed5[\"delayed_delay\"]\n",
        "X5 = delayed5.drop(columns=[\"delayed_delay\",\"arrival_delay\"])\n",
        "\n",
        "X5_train, X5_test, Y5_train, Y5_test = train_test_split(X5, Y5, test_size=0.2, random_state=42)\n",
        "\n",
        "Y10 = delayed5[\"delayed_delay\"]\n",
        "X10 = delayed5.drop(columns=[\"delayed_delay\",\"arrival_delay\"])\n",
        "\n",
        "X10_train, X10_test, Y10_train, Y10_test = train_test_split(X10, Y10, test_size=0.2, random_state=42)\n",
        "\n",
        "Y15 = delayed5[\"delayed_delay\"]\n",
        "X15 = delayed5.drop(columns=[\"delayed_delay\",\"arrival_delay\"])\n",
        "\n",
        "X15_train, X15_test, Y15_train, Y15_test = train_test_split(X15, Y15, test_size=0.2, random_state=42)\n",
        "\n",
        "Y20 = delayed5[\"delayed_delay\"]\n",
        "X20 = delayed5.drop(columns=[\"delayed_delay\",\"arrival_delay\"])\n",
        "\n",
        "X20_train, X20_test, Y20_train, Y20_test = train_test_split(X20, Y20, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jOQDV48Krb56"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Creation"
      ],
      "metadata": {
        "id": "zpvlA4uk12m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Model Training"
      ],
      "metadata": {
        "id": "vgUGYO-41_wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.0 Model Training Module 2 - Regression Models"
      ],
      "metadata": {
        "id": "X_9lSCGga0CM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear Regression"
      ],
      "metadata": {
        "id": "BeFR0fAYbU0u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJLNYI2Ka32h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVR Regression"
      ],
      "metadata": {
        "id": "UIH2dn2vbWbL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6T8_Q7Ca4qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGRegression Regression"
      ],
      "metadata": {
        "id": "G93hWXP4bhNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Sample\n",
        "X5_train_SAMPLE = X5_train.iloc[:500]\n",
        "X5_test_SAMPLE = X5_test.iloc[:500]\n",
        "\n",
        "Y5_train_SAMPLE = Y5_train.iloc[:500]\n",
        "Y5_test_SAMPLE = Y5_test.iloc[:500]\n",
        "\n",
        "Y5_SAMPLE = Y5_test.iloc[:500]\n",
        "X5_SAMPLE = Y5_test.iloc[:500]"
      ],
      "metadata": {
        "id": "bDGHkJxqaylV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this takes a while!\n",
        "params = {\n",
        "     'learning_rate': [0.01, 0.1, 0.2],\n",
        "     'n_estimators': [100, 200, 300],\n",
        "     'max_depth': [3, 4, 5],\n",
        "     'gamma':[.01,.1,1,10,100]\n",
        "\n",
        "}\n",
        "\n",
        "model =  XGBRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(model, params, cv=5, verbose=2, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the scaled training data\n",
        "grid_search.fit(X5_train_SAMPLE, Y5_train_SAMPLE)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "best_score = grid_search.best_score_\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cv_scores = cross_val_score(model, X5_SAMPLE , Y5_SAMPLE, cv=5, verbose=2).mean()\n",
        "print(cv_scores)\n",
        "\n",
        "model.fit(X5_train_SAMPLE, Y5_train_SAMPLE)\n",
        "y5_pred = model.predict(X5_test_SAMPLE)\n",
        "mae = mean_absolute_error(Y5_test_SAMPLE, y5_pred)\n",
        "mse = mean_squared_error(Y5_test_SAMPLE, y5_pred)\n",
        "r2 = r2_score(Y5_test_SAMPLE, y5_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y5_test_SAMPLE, y5_pred, alpha=0.5)  # Plot actual vs. predicted values\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values XGBRegressor\")\n",
        "\n",
        "# Add a diagonal line for reference (perfect predictions)\n",
        "plt.plot([min(Y5_test_SAMPLE), max(Y5_test_SAMPLE)], [min(Y5_test_SAMPLE), max(Y5_test_SAMPLE)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FvjjInNSbkgX",
        "outputId": "cff9ca88-eb1e-4a2a-9c97-a5fb1116ee38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.6s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
            "[CV] END gamma=0.01, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.4s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.5s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.01, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.6s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   1.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.5s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   1.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=1, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.6s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   1.2s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=10, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.2s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.6s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.3s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.5s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "[CV] END gamma=100, learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.1s\n",
            "Best Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
            "[CV] END .................................................... total time=   0.0s\n",
            "[CV] END .................................................... total time=   0.0s\n",
            "[CV] END .................................................... total time=   0.0s\n",
            "[CV] END .................................................... total time=   0.0s\n",
            "[CV] END .................................................... total time=   0.0s\n",
            "0.9950415355103907\n",
            "Mean Absolute Error: 0.33488745459535585\n",
            "Mean Squared Error: 0.2305519373008081\n",
            "R-squared: 0.7662310430087945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###KNN Regression"
      ],
      "metadata": {
        "id": "gy_Rm-wgbmRC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ibB5w61bnz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 Model Training Module 3 - Classification Models"
      ],
      "metadata": {
        "id": "WfUn1zhX2MZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1.1 One-Hot Encoding, Logistic Regression"
      ],
      "metadata": {
        "id": "My8HMN4qGJeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(1)LR\n",
        "params = {\n",
        "     'positive': [False,True],\n",
        "}\n",
        "model = LinearRegression()\n",
        "\n",
        "# Initialize a GridSearchCV object to perform hyperparameter tuning\n",
        "# - 'estimator': The machine learning model (in this case, 'model') to be tuned.\n",
        "# - 'param_grid': A dictionary specifying the hyperparameter grid to search.\n",
        "# - 'cv': The number of cross-validation folds (here, 5-fold cross-validation is used).\n",
        "# - 'scoring': The evaluation metric used to compare different hyperparameter settings\n",
        "# --('accuracy','precision','recall, etc. see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data to perform hyperparameter tuning\n",
        "grid_search.fit(X5_train, Y5_train)\n",
        "\n",
        "# Retrieve the best hyperparameters identified by the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "# Retrieve the best cross-validated accuracy score achieved with the best hyperparameters\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Set 'model' to be the best estimator (model with the best hyperparameters) identified by the grid search\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cmd.from_estimator(model, X5_test, Y5_test,cmap='Blues',colorbar=False)\n",
        "\n",
        "\n",
        "##---------------------Different measurements---------------------------\n",
        "print(f'Accuracy: {accuracy_score(Y5_test,model.predict(X5_test))}')\n",
        "print(f'Precision: {precision_score(Y5_test,model.predict(X5_test),average=None)}')\n",
        "print(f'Recall: {recall_score(Y5_test,model.predict(X5_test),average=None)}')"
      ],
      "metadata": {
        "id": "A2ka1YmuDUBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1.2 One-Hot Encoding, Logistic RegressionOne-Hot Coding & KNN"
      ],
      "metadata": {
        "id": "5pCbAF-7GbPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(2)KNN\n",
        "params = {\n",
        "     'n_neighbors': [3, 5, 7, 9],\n",
        "     'weights': ['uniform', 'distance']\n",
        "}\n",
        "model=KNeighborsClassifier()\n",
        "\n",
        "# Initialize a GridSearchCV object to perform hyperparameter tuning\n",
        "# - 'estimator': The machine learning model (in this case, 'model') to be tuned.\n",
        "# - 'param_grid': A dictionary specifying the hyperparameter grid to search.\n",
        "# - 'cv': The number of cross-validation folds (here, 5-fold cross-validation is used).\n",
        "# - 'scoring': The evaluation metric used to compare different hyperparameter settings\n",
        "# --('accuracy','precision','recall, etc. see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data to perform hyperparameter tuning\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters identified by the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "# Retrieve the best cross-validated accuracy score achieved with the best hyperparameters\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Set 'model' to be the best estimator (model with the best hyperparameters) identified by the grid search\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cmd.from_estimator(model, x_test, y_test,cmap='Blues',colorbar=False)\n",
        "\n",
        "\n",
        "##---------------------Different measurements---------------------------\n",
        "print(f'Accuracy: {accuracy_score(y_test,model.predict(x_test))}')\n",
        "print(f'Precision: {precision_score(y_test,model.predict(x_test),average=None)}')\n",
        "print(f'Recall: {recall_score(y_test,model.predict(x_test),average=None)}')"
      ],
      "metadata": {
        "id": "3yw9LmJgGd2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1.3 One-Hot Encoding, Logistic RegressionOne-Hot Coding & RF"
      ],
      "metadata": {
        "id": "TWR7__piGgtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(3)RF\n",
        "params = {\n",
        "     'n_estimators': [100, 200, 300],\n",
        "     'max_depth': [None, 10, 20, 30],\n",
        "     'min_samples_split': [2, 5, 10],\n",
        "     'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Initialize a GridSearchCV object to perform hyperparameter tuning\n",
        "# - 'estimator': The machine learning model (in this case, 'model') to be tuned.\n",
        "# - 'param_grid': A dictionary specifying the hyperparameter grid to search.\n",
        "# - 'cv': The number of cross-validation folds (here, 5-fold cross-validation is used).\n",
        "# - 'scoring': The evaluation metric used to compare different hyperparameter settings\n",
        "# --('accuracy','precision','recall, etc. see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data to perform hyperparameter tuning\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters identified by the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "# Retrieve the best cross-validated accuracy score achieved with the best hyperparameters\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Set 'model' to be the best estimator (model with the best hyperparameters) identified by the grid search\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cmd.from_estimator(model, x_test, y_test,cmap='Blues',colorbar=False)\n",
        "\n",
        "\n",
        "##---------------------Different measurements---------------------------\n",
        "print(f'Accuracy: {accuracy_score(y_test,model.predict(x_test))}')\n",
        "print(f'Precision: {precision_score(y_test,model.predict(x_test),average=None)}')\n",
        "print(f'Recall: {recall_score(y_test,model.predict(x_test),average=None)}')"
      ],
      "metadata": {
        "id": "-yqyURqNGjsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1.4 One-Hot Encoding, Logistic RegressionOne-Hot Coding & XGBoost"
      ],
      "metadata": {
        "id": "0UGJCHZKGu_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(4)XGBoost\n",
        "params = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "map = {'air': 0, 'bus': 1, 'car': 2,'rail':3}\n",
        "y_train = y_train.map(map)\n",
        "y_test = y_test.map(map)\n",
        "model =  XGBClassifier()\n",
        "\n",
        "# Initialize a GridSearchCV object to perform hyperparameter tuning\n",
        "# - 'estimator': The machine learning model (in this case, 'model') to be tuned.\n",
        "# - 'param_grid': A dictionary specifying the hyperparameter grid to search.\n",
        "# - 'cv': The number of cross-validation folds (here, 5-fold cross-validation is used).\n",
        "# - 'scoring': The evaluation metric used to compare different hyperparameter settings\n",
        "# --('accuracy','precision','recall, etc. see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data to perform hyperparameter tuning\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters identified by the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "# Retrieve the best cross-validated accuracy score achieved with the best hyperparameters\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Set 'model' to be the best estimator (model with the best hyperparameters) identified by the grid search\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cmd.from_estimator(model, x_test, y_test,cmap='Blues',colorbar=False)\n",
        "\n",
        "\n",
        "##---------------------Different measurements---------------------------\n",
        "print(f'Accuracy: {accuracy_score(y_test,model.predict(x_test))}')\n",
        "print(f'Precision: {precision_score(y_test,model.predict(x_test),average=None)}')\n",
        "print(f'Recall: {recall_score(y_test,model.predict(x_test),average=None)}')"
      ],
      "metadata": {
        "id": "V-JKROW-GxTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1.5 One-Hot Encoding, Logistic RegressionOne-Hot Coding & SVM"
      ],
      "metadata": {
        "id": "2Q6oCLcjG5V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(5)SVM\n",
        "## Note: It will costs a long time.\n",
        "params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "}\n",
        "\n",
        "\n",
        "model= SVC(kernel=\"linear\")\n",
        "\n",
        "# Initialize a GridSearchCV object to perform hyperparameter tuning\n",
        "# - 'estimator': The machine learning model (in this case, 'model') to be tuned.\n",
        "# - 'param_grid': A dictionary specifying the hyperparameter grid to search.\n",
        "# - 'cv': The number of cross-validation folds (here, 5-fold cross-validation is used).\n",
        "# - 'scoring': The evaluation metric used to compare different hyperparameter settings\n",
        "# --('accuracy','precision','recall, etc. see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data to perform hyperparameter tuning\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters identified by the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "# Retrieve the best cross-validated accuracy score achieved with the best hyperparameters\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Set 'model' to be the best estimator (model with the best hyperparameters) identified by the grid search\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "cmd.from_estimator(model, x_test, y_test,cmap='Blues',colorbar=False)\n",
        "\n",
        "\n",
        "##---------------------Different measurements---------------------------\n",
        "print(f'Accuracy: {accuracy_score(y_test,model.predict(x_test))}')\n",
        "print(f'Precision: {precision_score(y_test,model.predict(x_test),average=None)}')\n",
        "print(f'Recall: {recall_score(y_test,model.predict(x_test),average=None)}')"
      ],
      "metadata": {
        "id": "MtDr58PcG22W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Model Training Module 5 - Clustering Models"
      ],
      "metadata": {
        "id": "CrRDymQ52tJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2.1 KMeans"
      ],
      "metadata": {
        "id": "gA2IyOWnHSwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SC_score = []\n",
        "DB_score = []\n",
        "CH_score = []\n",
        "\n",
        "for i in range(2,11):\n",
        "    print('\\033[1m' + \"KMeans: n_clusters=\" + str(i) + '\\033[0m')\n",
        "    clusters = KMeans(n_clusters=i, random_state=0, n_init=10).fit(vectorized_day_dataset_no_nans)\n",
        "\n",
        "    if clusters is not None:\n",
        "            cluster_labels = clusters.labels_\n",
        "\n",
        "    # Calculate the Silhouette Score\n",
        "    SC_score.append(silhouette_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Silhouette Score measures the quality of clusters, higher values indicate better separation.\n",
        "\n",
        "    # Calculate the Davies-Bouldin Score\n",
        "    DB_score.append(davies_bouldin_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Davies-Bouldin Score measures the average similarity between each cluster and its most similar cluster, lower values indicate better separation.\n",
        "\n",
        "    # Calculate the Calinski-Harabasz Score\n",
        "    CH_score.append(calinski_harabasz_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Calinski-Harabasz Score measures the ratio of between-cluster variance to within-cluster variance, higher values indicate better separation.\n",
        "\n",
        "    # Print the computed cluster quality scores\n",
        "    print('Silhouette Score:', SC_score[-1])\n",
        "    print('Davies-Bouldin Score:', DB_score[-1])\n",
        "    print('Calinski-Harabasz Score:', CH_score[-1])\n",
        "\n",
        "# List of cluster numbers\n",
        "cluster_range = list(range(2, 11))\n",
        "\n",
        "# Silhouette Score Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(cluster_range, SC_score, marker='o')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "# Davies-Bouldin Score Plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(cluster_range, DB_score, marker='o', color='red')\n",
        "plt.title('Davies-Bouldin Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Davies-Bouldin Score')\n",
        "\n",
        "# Calinski-Harabasz Score Plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(cluster_range, CH_score, marker='o', color='green')\n",
        "plt.title('Calinski-Harabasz Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Calinski-Harabasz Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLTlEkzBHUfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2.2 Agglomerative Clustering"
      ],
      "metadata": {
        "id": "PhrETBqvHW5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SC_score = []\n",
        "DB_score = []\n",
        "CH_score = []\n",
        "\n",
        "for i in range(2,11):\n",
        "    print('\\033[1m' + \"Agglomerative Clustering: n_clusters=\" + str(i) + '\\033[0m')\n",
        "    clusters = AgglomerativeClustering(n_clusters=i, linkage='ward').fit(vectorized_day_dataset_no_nans)\n",
        "\n",
        "    if clusters is not None:\n",
        "            cluster_labels = clusters.labels_\n",
        "\n",
        "    # Calculate the Silhouette Score\n",
        "    SC_score.append(silhouette_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Silhouette Score measures the quality of clusters, higher values indicate better separation.\n",
        "\n",
        "    # Calculate the Davies-Bouldin Score\n",
        "    DB_score.append(davies_bouldin_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Davies-Bouldin Score measures the average similarity between each cluster and its most similar cluster, lower values indicate better separation.\n",
        "\n",
        "    # Calculate the Calinski-Harabasz Score\n",
        "    CH_score.append(calinski_harabasz_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Calinski-Harabasz Score measures the ratio of between-cluster variance to within-cluster variance, higher values indicate better separation.\n",
        "\n",
        "    # Print the computed cluster quality scores\n",
        "    print('Silhouette Score:', SC_score[-1])\n",
        "    print('Davies-Bouldin Score:', DB_score[-1])\n",
        "    print('Calinski-Harabasz Score:', CH_score[-1])\n",
        "\n",
        "# List of cluster numbers\n",
        "cluster_range = list(range(2, 11))\n",
        "\n",
        "# Silhouette Score Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(cluster_range, SC_score, marker='o')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "# Davies-Bouldin Score Plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(cluster_range, DB_score, marker='o', color='red')\n",
        "plt.title('Davies-Bouldin Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Davies-Bouldin Score')\n",
        "\n",
        "# Calinski-Harabasz Score Plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(cluster_range, CH_score, marker='o', color='green')\n",
        "plt.title('Calinski-Harabasz Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Calinski-Harabasz Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k10UaH7MHaCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2.3 DBSCAN"
      ],
      "metadata": {
        "id": "DUqmJaDXHZPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SC_score = []\n",
        "DB_score = []\n",
        "CH_score = []\n",
        "\n",
        "for i in range(400, 1501, 100):\n",
        "    print('\\033[1m' + \"DBSCAN: eps=\" + str(i) + '\\033[0m')  # changed n_clusters to eps for clarity\n",
        "    clusters = DBSCAN(eps=i, min_samples=2).fit(vectorized_day_dataset_no_nans)\n",
        "\n",
        "    if clusters is not None:\n",
        "        cluster_labels = clusters.labels_\n",
        "\n",
        "        # Check if valid clusters formed\n",
        "        if len(set(cluster_labels)) > 1:\n",
        "            SC_score.append(silhouette_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "            DB_score.append(davies_bouldin_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "            CH_score.append(calinski_harabasz_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "        else:\n",
        "            SC_score.append(float('nan'))\n",
        "            DB_score.append(float('nan'))\n",
        "            CH_score.append(float('nan'))\n",
        "\n",
        "        # Print the computed cluster quality scores\n",
        "        print('Silhouette Score:', SC_score[-1])\n",
        "        print('Davies-Bouldin Score:', DB_score[-1])\n",
        "        print('Calinski-Harabasz Score:', CH_score[-1])\n",
        "\n",
        "# List of eps values\n",
        "eps_range = list(range(400, 1501, 100))\n",
        "\n",
        "# Silhouette Score Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(eps_range, SC_score, marker='o')\n",
        "plt.title('Silhouette Score vs. Eps')\n",
        "plt.xlabel('Eps')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "# Davies-Bouldin Score Plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(eps_range, DB_score, marker='o', color='red')\n",
        "plt.title('Davies-Bouldin Score vs. Eps')\n",
        "plt.xlabel('Eps')\n",
        "plt.ylabel('Davies-Bouldin Score')\n",
        "\n",
        "# Calinski-Harabasz Score Plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(eps_range, CH_score, marker='o', color='green')\n",
        "plt.title('Calinski-Harabasz Score vs. Eps')\n",
        "plt.xlabel('Eps')\n",
        "plt.ylabel('Calinski-Harabasz Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dr0dahIRHZgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2.4 Gaussian Mixture"
      ],
      "metadata": {
        "id": "mjAX2xSHHqH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SC_score = []\n",
        "DB_score = []\n",
        "CH_score = []\n",
        "\n",
        "for i in range(2,11):\n",
        "    print('\\033[1m' + \"Gaussian Mixture: n_clusters=\" + str(i) + '\\033[0m')\n",
        "    cluster_labels = GaussianMixture(n_components=i).fit(vectorized_day_dataset_no_nans).predict(vectorized_day_dataset_no_nans)\n",
        "\n",
        "    # Calculate the Silhouette Score\n",
        "    SC_score.append(silhouette_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Silhouette Score measures the quality of clusters, higher values indicate better separation.\n",
        "\n",
        "    # Calculate the Davies-Bouldin Score\n",
        "    DB_score.append(davies_bouldin_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Davies-Bouldin Score measures the average similarity between each cluster and its most similar cluster, lower values indicate better separation.\n",
        "\n",
        "    # Calculate the Calinski-Harabasz Score\n",
        "    CH_score.append(calinski_harabasz_score(vectorized_day_dataset_no_nans, cluster_labels))\n",
        "    # Calinski-Harabasz Score measures the ratio of between-cluster variance to within-cluster variance, higher values indicate better separation.\n",
        "\n",
        "    # Print the computed cluster quality scores\n",
        "    print('Silhouette Score:', SC_score[-1])\n",
        "    print('Davies-Bouldin Score:', DB_score[-1])\n",
        "    print('Calinski-Harabasz Score:', CH_score[-1])\n",
        "\n",
        "# List of cluster numbers\n",
        "cluster_range = list(range(2, 11))\n",
        "\n",
        "# Silhouette Score Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(cluster_range, SC_score, marker='o')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "# Davies-Bouldin Score Plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(cluster_range, DB_score, marker='o', color='red')\n",
        "plt.title('Davies-Bouldin Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Davies-Bouldin Score')\n",
        "\n",
        "# Calinski-Harabasz Score Plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(cluster_range, CH_score, marker='o', color='green')\n",
        "plt.title('Calinski-Harabasz Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Calinski-Harabasz Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2ighYOqHqpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2.5 Finding the Optimal Clustering Model for Prediction"
      ],
      "metadata": {
        "id": "xeHf-hD3H4YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,5):\n",
        "    if i == 1:\n",
        "        print('\\033[1m' + \"KMeans:\" + '\\033[0m')\n",
        "        clusters = KMeans(n_clusters=2, random_state=0, n_init=10).fit(vectorized_day_dataset_no_nans) # check the parameters at https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "    elif i == 2:\n",
        "        print('\\033[1m' + \"Agglomerative Clustering:\" + '\\033[0m')\n",
        "        clusters = AgglomerativeClustering(n_clusters=2, linkage='ward').fit(vectorized_day_dataset_no_nans) # check the parameters at https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
        "    elif i == 3:\n",
        "        print('\\033[1m' + \"DBSCAN:\" + '\\033[0m')\n",
        "        clusters = DBSCAN(eps=1500, min_samples = 5, metric='euclidean').fit(vectorized_day_dataset_no_nans) # check the parameters at https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
        "\n",
        "    if 0 < i < 4:\n",
        "        if clusters is not None:\n",
        "            cluster_labels = clusters.labels_\n",
        "    elif i == 4:\n",
        "        print('\\033[1m' + \"GaussianMixture:\" + '\\033[0m')\n",
        "        cluster_labels = GaussianMixture(n_components=2).fit(vectorized_day_dataset_no_nans).predict(vectorized_day_dataset_no_nans) #check the parameters at  https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_init.html#sphx-glr-auto-examples-mixture-plot-gmm-init-py\n",
        "\n",
        "\n",
        "    #print(cluster_labels)\n",
        "\n",
        "    # Calculate the number of clusters by finding unique values in 'cluster_labels'\n",
        "    n_clusters_t = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
        "\n",
        "    # Assign colors to days based on clusters\n",
        "    days_colors, color_to_cluster, style_to_cluster = assign_colors(n_clusters_t, days_not_nans, cluster_labels)\n",
        "    # The function 'assign_colors' is used to determine colors and styles for visualization.\n",
        "\n",
        "    # Create a calendar visualization figure\n",
        "    make_calendar_visualization_figure(days_not_nans, cluster_labels, n_clusters_t, [2021], days_colors,\n",
        "                                   color_to_cluster, save_figure=None)\n",
        "\n",
        "    # Initialize a list to store centroid data\n",
        "    centroids = []\n",
        "\n",
        "    # Calculate centroids for each cluster\n",
        "    for i in range(0, n_clusters_t):\n",
        "        centroid = np.nanmean(vectorized_day_dataset_no_nans[np.where(cluster_labels == i)[0], :], 0).reshape(1, nintvals)\n",
        "        centroids.append(centroid)\n",
        "\n",
        "    # Define the number of past intervals to consider for classification\n",
        "    n_past_intervals_for_classification = 5\n",
        "\n",
        "    # Initialize variables to calculate accuracy metrics\n",
        "    total_mae = 0\n",
        "    total_mape = 0\n",
        "    prediction_counts = 0\n",
        "\n",
        "    # Loop through each day in the evaluation dataset with no missing values\n",
        "    for i in range(0, ndays_eval_not_nans):\n",
        "        # Loop through intervals from n_past_intervals_for_classification to nintvals - 1\n",
        "        for j in range(n_past_intervals_for_classification, nintvals - 1):\n",
        "            # Find the closest centroid for the current data point\n",
        "            centroid_index = find_the_closest_centroid(centroids, vectorized_day_dataset_no_nans_eval[i].reshape(1, nintvals), j - n_past_intervals_for_classification, j)\n",
        "\n",
        "            # Predict the value for the next interval\n",
        "            predicted_value = centroids[centroid_index][0, j + 1]\n",
        "\n",
        "            # Calculate Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE)\n",
        "            mae_t = abs(predicted_value - vectorized_day_dataset_no_nans_eval[i][j + 1])\n",
        "            mape_t = abs(predicted_value - vectorized_day_dataset_no_nans_eval[i][j + 1]) / float(vectorized_day_dataset_no_nans_eval[i][j + 1])\n",
        "\n",
        "            # Accumulate MAE, MAPE, and count of predictions\n",
        "            total_mae += mae_t\n",
        "            total_mape += mape_t\n",
        "            prediction_counts += 1\n",
        "\n",
        "    # Calculate and print the prediction accuracy metrics\n",
        "    print('Prediction accuracy MAE:', total_mae / prediction_counts)\n",
        "    print('Prediction accuracy MAPE:', total_mape / prediction_counts)"
      ],
      "metadata": {
        "id": "anvyw4fjH3uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3  Model Training Module 6 - Do we need to make Reduction?"
      ],
      "metadata": {
        "id": "akyHOGSV3gDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 Model Training Module 7 - Nural Network Models"
      ],
      "metadata": {
        "id": "NozcLnbC3ynB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------network construction------------------------------------------------------------------\n",
        "\n",
        "# Initialize an empty DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Layers\", \"Dropout Rate\", \"Learning Rate\", \"MAE\"])\n",
        "\n",
        "# Search parameters\n",
        "layer_configs = [[32, 64], [64, 128, 64], [128, 256, 128, 64]]\n",
        "dropout_rates = [0.2, 0.3, 0.4]\n",
        "learning_rates = [0.001, 0.0001]\n",
        "\n",
        "for config in layer_configs:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        for learning_rate in learning_rates:\n",
        "\n",
        "            model = Sequential()\n",
        "\n",
        "            # Add layers from config\n",
        "            model.add(Dense(config[0], activation='relu', input_dim=22))\n",
        "            for units in config[1:]:\n",
        "                model.add(Dense(units, activation='relu'))\n",
        "                model.add(Dropout(dropout_rate))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n",
        "\n",
        "            # Callbacks\n",
        "            early_stop = EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=3)\n",
        "\n",
        "            # Train without verbose and without ModelCheckpoint for simplicity\n",
        "            hist = model.fit(X5_train, Y5_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stop, reduce_lr], verbose=0)\n",
        "\n",
        "            val_mae = min(hist.history['val_mae'])\n",
        "\n",
        "            # Append results to the DataFrame\n",
        "            results_df = results_df.append({\n",
        "                \"Layers\": str(config),\n",
        "                \"Dropout Rate\": dropout_rate,\n",
        "                \"Learning Rate\": learning_rate,\n",
        "                \"MAE\": val_mae\n",
        "            }, ignore_index=True)\n",
        "\n",
        "# Print the results in a tabular form\n",
        "print(results_df)\n",
        "\n",
        "# To find the best configuration, sort the DataFrame based on MAE\n",
        "best_row = results_df.sort_values(by=\"MAE\").iloc[0]\n",
        "print(\"\\nBest Configuration:\")\n",
        "print(best_row)"
      ],
      "metadata": {
        "id": "hLc1FeMtKtaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Model Evaluation"
      ],
      "metadata": {
        "id": "PRdGKyY23-yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What type of model is the best performer?"
      ],
      "metadata": {
        "id": "FBKeCX134Iix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Optimization"
      ],
      "metadata": {
        "id": "2ioson3M4hNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization of the parameters of the best performing model type."
      ],
      "metadata": {
        "id": "jCr0p-x05AF0"
      }
    }
  ]
}